/*
 *  Orca-Base: Components for robotics.
 *
 *  Copyright (C) 2004
 *
 *  This library is free software; you can redistribute it and/or
 *  modify it under the terms of the GNU Lesser General Public
 *  License as published by the Free Software Foundation; either
 *  version 2.1 of the License, or (at your option) any later version.
 *
 *  This library is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 *  Lesser General Public License for more details.
 *
 *  You should have received a copy of the GNU Lesser General Public
 *  License along with this library; if not, write to the Free Software
 *  Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
 */

/*!

@page orca_doc_quickstart Quick-Start Guide

@note revised for Orca2 release 2.0.0.

This page describes how to get a quick demonstration up and running with your new Orca install.

Before you begin, make sure that you've installed Orca (see @ref orca_doc_getting ).

@section startup Starting Up the Infrastructure

We'll be using sample configuration files which are distributed with Orca. As the general rule, you shouldn't work or run programs from the distribution. So we'll create a separate directory and copy config files into it.
@verbatim
$ cd ~
$ mkdir sys
@endverbatim

@par IcePack Registry

The IcePack Registry provides a Naming service: a mapping from logical port names to physical addresses. It's currently the only way for components to find one another. We create a separate directory for it to run in, copy a sample config file, create the database directory and start it up.
@verbatim
$ cd ~/sys; mkdir icereg; cd icereg
$ cp [ORCA2]/doc/icecfg/icepack.cfg .
$ mkdir db
$ icepackregistry --Ice.Config=icepack.cfg
@endverbatim

This starts icepackregistry on your local machine.  If you're going to be using Orca a lot,
it's probably a good idea to set this up so it's always running on a single machine on the network.

@par IceStorm Service

There should be exactly one IceStorm service per host.  This is an event service, used to decouple publishers from subscribers. We create a separate directory for it to run in, copy a sample config file, create the database directory and start it up.
@verbatim
$ cd ~/sys; mkdir icestorm; cd icestorm
$ cp [ORCA2]/doc/icecfg/icebox_icestorm.cfg .
$ mkdir stormdb
$ icebox --Ice.Config=icebox_icestorm.cfg
@endverbatim

@section point Pointing Components at this Infrastructure

When an Orca component starts up, it needs to know how to find the
services above.

If your components use orcaiceutil, you can solve this problem
centrally by putting the following in your '~/.orcarc' file:
@verbatim
# Standard Ice Configuration for Orca
Ice.Default.Locator=IcePack/Locator:default -p 12000
IceStorm.TopicManager.Proxy=IceStorm/TopicManager:default -p 10000
@endverbatim
(modify appropriately if this differs from your system setup)


@section talk Getting Two Components Talking

For a first demonstration, try connecting a fake sicklaser to a laser
monitoring component.

First, copy all configuration files to your sys directory you created before:
@verbatim
$ cp [ORCA2]/orca/cfg/* ~/sys
@endverbatim

Then, configure the laser for fake operation (or skip this step if
you're connected to a real SICK laser).  Edit
'sicklaser.cfg', and replace the line:

@verbatim
Config.Driver=native
@endverbatim

with:

@verbatim
Config.Driver=fake
@endverbatim

Then start the laser:

@verbatim
$ cd ~/sys
$ sicklaser sicklaser.cfg
@endverbatim
(You need to have the sicklaser component built and installed before).

Now start a new shell, and fire up lasermon (a laser monitoring component):

@verbatim
$ cd ~/sys
$ lasermon lasermon.cfg
@endverbatim

You should see the scans scroll by on the screen.  Congratulations,
your first two components are talking!  

*/
